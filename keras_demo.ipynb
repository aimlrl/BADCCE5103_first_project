{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 10:14:45.033980: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-16 10:14:45.488750: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-16 10:14:45.491137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-16 10:14:47.755895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import kaggle as kg\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"] = \"aimlrl\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"54d4150a6ca782d7b27af3f3754eddd8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.api.dataset_download_files(dataset=\"medahmedkrichen/devanagari-handwritten-character-datase\",\n",
    "                              path=\"dataset\",unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df(path):\n",
    "\n",
    "    img_path = list()\n",
    "    img_label = list()\n",
    "\n",
    "    for single_class_dir_path in pathlib.Path(path).glob(\"*\"):\n",
    "\n",
    "        for single_class_img_path in pathlib.Path(single_class_dir_path).glob(\"*.png\"):\n",
    "\n",
    "            img_path.append(str(single_class_img_path))\n",
    "            #print(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "            img_label.append(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "\n",
    "    return pd.DataFrame(data={\"img_path\":img_path,\"label\":img_label})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"dataset/DevanagariHandwrittenCharacterDataset/Train\"\n",
    "test_path = \"dataset/DevanagariHandwrittenCharacterDataset/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_test_df(train_path)\n",
    "testing_data = train_test_df(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "character2int = dict(zip(training_data[\"label\"].unique(),range(len(training_data[\"label\"].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30416/1986340858.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  training_data[\"label\"].replace(to_replace=character2int.keys(),value=character2int.values(),\n",
      "/tmp/ipykernel_30416/1986340858.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  training_data[\"label\"].replace(to_replace=character2int.keys(),value=character2int.values(),\n",
      "/tmp/ipykernel_30416/1986340858.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  testing_data.replace(to_replace=character2int.keys(),value=character2int.values(),\n"
     ]
    }
   ],
   "source": [
    "training_data[\"label\"].replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                               inplace=True)\n",
    "\n",
    "testing_data.replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                     inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_train = to_categorical(y=training_data[\"label\"],num_classes=46)\n",
    "Y_true_test = to_categorical(y=testing_data[\"label\"],num_classes=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_dnn():\n",
    "\n",
    "    input_to_dnn = Input(shape=(1024,))\n",
    "    first_dense_out = Dense(units=1024,activation=\"relu\") (input_to_dnn)\n",
    "    output = Dense(units=46,activation=\"softmax\") (first_dense_out)\n",
    "\n",
    "    return Model(inputs=[input_to_dnn],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(data_df, Y_true, mb_size):\n",
    "\n",
    "    for time_step in range(data_df.shape[0]//mb_size):\n",
    "        X_mb = list()\n",
    "\n",
    "        for img_path in data_df.iloc[time_step*mb_size:(time_step+1)*mb_size,0]:\n",
    "\n",
    "            img_np_array = plt.imread(img_path)\n",
    "            reshaped_np_array = img_np_array.reshape(1024,)\n",
    "            X_mb.append(reshaped_np_array)\n",
    "\n",
    "        X_mb = np.array(X_mb)\n",
    "        Y_true_mb = Y_true[time_step*mb_size:(time_step+1)*mb_size]\n",
    "\n",
    "        yield X_mb, Y_true_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "training_data_mb_size = 782\n",
    "testing_data_mb_size = 138\n",
    "training_data_generator = custom_data_generator(training_data,Y_true_train,training_data_mb_size)\n",
    "testing_data_generator = custom_data_generator(testing_data,Y_true_test,testing_data_mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1024)]            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 46)                47150     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1096750 (4.18 MB)\n",
      "Trainable params: 1096750 (4.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_dnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(Y_true_mb,Y_pred_mb):\n",
    "\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true=Y_true_mb,\n",
    "                                                                   y_pred=Y_pred_mb))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(X_true_train_mb,Y_true_train_mb):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "            \n",
    "        Y_pred_train_mb = model(X_train_mb, training=True)\n",
    "        training_loss = loss_fn(Y_true_train_mb, Y_pred_train_mb)\n",
    "\n",
    "    grads = tape.gradient(training_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    train_acc_metric.update_state(Y_true_train_mb,Y_pred_train_mb)\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def testing_forward_pass(X_test_mb,Y_true_test_mb):\n",
    "\n",
    "    Y_pred_test_mb = model(X_test_mb,training=False)\n",
    "    testing_loss = loss_fn(Y_true_test_mb,Y_pred_test_mb)\n",
    "    test_acc_metric.update_state(Y_true_test_mb,Y_pred_test_mb)\n",
    "\n",
    "    return testing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time Step 50, Training loss for one mini batch: 3.6818\n",
      "Epoch 1, Time Step 100, Training loss for one mini batch: 3.6165\n",
      "Epoch 1, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 1, Testing Loss for last mini batch: 2.9984\n",
      "Epoch 1, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2, Time Step 50, Training loss for one mini batch: 3.6607\n",
      "Epoch 2, Time Step 100, Training loss for one mini batch: 3.5965\n",
      "Epoch 2, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 2, Testing Loss for last mini batch: 2.9686\n",
      "Epoch 2, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3, Time Step 50, Training loss for one mini batch: 3.6386\n",
      "Epoch 3, Time Step 100, Training loss for one mini batch: 3.5748\n",
      "Epoch 3, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 3, Testing Loss for last mini batch: 2.9376\n",
      "Epoch 3, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4, Time Step 50, Training loss for one mini batch: 3.6175\n",
      "Epoch 4, Time Step 100, Training loss for one mini batch: 3.5518\n",
      "Epoch 4, Training Accuracy: 0.00\n",
      "\n",
      "Epoch 4, Testing Loss for last mini batch: 2.9064\n",
      "Epoch 4, Testing Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5, Time Step 50, Training loss for one mini batch: 3.5956\n",
      "Epoch 5, Time Step 100, Training loss for one mini batch: 3.5280\n",
      "Epoch 5, Training Accuracy: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m train_acc_metric\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[1;32m     19\u001b[0m testing_data_generator \u001b[38;5;241m=\u001b[39m custom_data_generator(testing_data,Y_true_test,testing_data_mb_size)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_test_mb, Y_true_test_mb \u001b[38;5;129;01min\u001b[39;00m testing_data_generator:\n\u001b[1;32m     22\u001b[0m     testing_loss \u001b[38;5;241m=\u001b[39m testing_forward_pass(X_test_mb,Y_true_test_mb)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Testing Loss for last mini batch: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mfloat\u001b[39m(testing_loss)))\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mcustom_data_generator\u001b[0;34m(data_df, Y_true, mb_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m X_mb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m data_df\u001b[38;5;241m.\u001b[39miloc[time_step\u001b[38;5;241m*\u001b[39mmb_size:(time_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mmb_size,\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m     img_np_array \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     reshaped_np_array \u001b[38;5;241m=\u001b[39m img_np_array\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1024\u001b[39m,)\n\u001b[1;32m     10\u001b[0m     X_mb\u001b[38;5;241m.\u001b[39mappend(reshaped_np_array)\n",
      "File \u001b[0;32m~/AiML-Projects/BADCCE5103_first_project/.venv/lib/python3.10/site-packages/matplotlib/pyplot.py:2511\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\n\u001b[1;32m   2509\u001b[0m         fname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath \u001b[38;5;241m|\u001b[39m BinaryIO, \u001b[38;5;28mformat\u001b[39m: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2510\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AiML-Projects/BADCCE5103_first_project/.venv/lib/python3.10/site-packages/matplotlib/image.py:1544\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1543\u001b[0m         )\n\u001b[0;32m-> 1544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m   1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1546\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/AiML-Projects/BADCCE5103_first_project/.venv/lib/python3.10/site-packages/PIL/ImageFile.py:125\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodermaxblock \u001b[38;5;241m=\u001b[39m MAXBLOCK\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    training_data_generator = custom_data_generator(training_data,Y_true_train,782)\n",
    "\n",
    "    for time_step, (X_train_mb, Y_true_train_mb) in enumerate(training_data_generator):\n",
    "        training_loss = training_step(X_train_mb,Y_true_train_mb)\n",
    "\n",
    "        if (time_step+1) % 50 == 0:\n",
    "            print(\"Epoch %d, Time Step %d, Training loss for one mini batch: %.4f\"\n",
    "            % (epoch+1, time_step+1, float(training_loss)))\n",
    "            \n",
    "    training_acc = train_acc_metric.result()    \n",
    "    print(\"Epoch %d, Training Accuracy: %.2f\" % (epoch+1,float(training_acc)))\n",
    "    train_acc_metric.reset_state()\n",
    "\n",
    "    testing_data_generator = custom_data_generator(testing_data,Y_true_test,testing_data_mb_size)\n",
    "\n",
    "    for X_test_mb, Y_true_test_mb in testing_data_generator:\n",
    "        testing_loss = testing_forward_pass(X_test_mb,Y_true_test_mb)\n",
    "\n",
    "    print(\"\\nEpoch %d, Testing Loss for last mini batch: %.4f\" % (epoch+1,float(testing_loss)))\n",
    "    testing_acc = test_acc_metric.result()\n",
    "    print(\"Epoch %d, Testing Accuracy: %.2f\" % (epoch+1,float(testing_acc)))\n",
    "    test_acc_metric.reset_state()\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
