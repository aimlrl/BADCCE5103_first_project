{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle as kg\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"] = \"aimlrl\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"54d4150a6ca782d7b27af3f3754eddd8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.api.dataset_download_files(dataset=\"medahmedkrichen/devanagari-handwritten-character-datase\",\n",
    "                              path=\"dataset\",unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df(path):\n",
    "\n",
    "    img_path = list()\n",
    "    img_label = list()\n",
    "\n",
    "    for single_class_dir_path in pathlib.Path(path).glob(\"*\"):\n",
    "\n",
    "        for single_class_img_path in pathlib.Path(single_class_dir_path).glob(\"*.png\"):\n",
    "\n",
    "            img_path.append(str(single_class_img_path))\n",
    "            #print(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "            img_label.append(str(single_class_img_path).split(\"/\")[-2].split(\"_\")[-1])\n",
    "\n",
    "    return pd.DataFrame(data={\"img_path\":img_path,\"label\":img_label})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"dataset/DevanagariHandwrittenCharacterDataset/Train\"\n",
    "test_path = \"dataset/DevanagariHandwrittenCharacterDataset/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_test_df(train_path)\n",
    "testing_data = train_test_df(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character2int = dict(zip(training_data[\"label\"].unique(),range(len(training_data[\"label\"].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"label\"].replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                               inplace=True)\n",
    "\n",
    "testing_data.replace(to_replace=character2int.keys(),value=character2int.values(),\n",
    "                     inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_train = to_categorical(y=training_data[\"label\"],num_classes=46)\n",
    "Y_true_test = to_categorical(y=testing_data[\"label\"],num_classes=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_dnn():\n",
    "\n",
    "    input_to_dnn = Input(shape=(1024,))\n",
    "    first_dense_out = Dense(units=1024,activation=\"relu\")(input_to_dnn)\n",
    "    second_dense_out = Dense(units=1024,activation=\"relu\")(first_dense_out)\n",
    "    second_dense_out = BatchNormalization()(second_dense_out)\n",
    "    output = Dense(units=46,activation=\"softmax\")(second_dense_out)\n",
    "\n",
    "    return Model(inputs=[input_to_dnn],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(data_df, Y_true, mb_size):\n",
    "\n",
    "    for time_step in range(data_df.shape[0]//mb_size):\n",
    "        X_mb = list()\n",
    "\n",
    "        for img_path in data_df.iloc[time_step*mb_size:(time_step+1)*mb_size,0]:\n",
    "\n",
    "            img_np_array = plt.imread(img_path)\n",
    "            reshaped_np_array = img_np_array.reshape(1024,)\n",
    "            X_mb.append(reshaped_np_array)\n",
    "\n",
    "        X_mb = np.array(X_mb)\n",
    "        Y_true_mb = Y_true[time_step*mb_size:(time_step+1)*mb_size]\n",
    "\n",
    "        yield X_mb, Y_true_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "training_data_mb_size = 782\n",
    "testing_data_mb_size = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multiclass_dnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(Y_true_mb,Y_pred_mb):\n",
    "\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true=Y_true_mb,\n",
    "                                                                          y_pred=Y_pred_mb))\n",
    "\n",
    "optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(X_train_mb,Y_true_train_mb):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "            \n",
    "        Y_pred_train_mb = model(X_train_mb, training=True)\n",
    "        training_loss = loss_fn(Y_true_train_mb, Y_pred_train_mb)\n",
    "\n",
    "    grads = tape.gradient(training_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    train_acc_metric.update_state(Y_true_train_mb,Y_pred_train_mb)\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def testing_forward_pass(X_test_mb,Y_true_test_mb):\n",
    "\n",
    "    Y_pred_test_mb = model(X_test_mb,training=False)\n",
    "    testing_loss = loss_fn(Y_true_test_mb,Y_pred_test_mb)\n",
    "    test_acc_metric.update_state(Y_true_test_mb,Y_pred_test_mb)\n",
    "\n",
    "    return testing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    training_data_generator = custom_data_generator(training_data,Y_true_train,782)\n",
    "\n",
    "    for time_step, (X_train_mb, Y_true_train_mb) in enumerate(training_data_generator):\n",
    "        training_loss = training_step(X_train_mb,Y_true_train_mb)\n",
    "\n",
    "        if (time_step+1) % 50 == 0:\n",
    "            print(\"Epoch %d, Time Step %d, Training loss for one mini batch: %.4f\"\n",
    "            % (epoch+1, time_step+1, float(training_loss)))\n",
    "            \n",
    "    training_acc = train_acc_metric.result()    \n",
    "    print(\"Epoch %d, Training Accuracy: %.2f\" % (epoch+1,float(training_acc)))\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    testing_data_generator = custom_data_generator(testing_data,Y_true_test,testing_data_mb_size)\n",
    "\n",
    "    for X_test_mb, Y_true_test_mb in testing_data_generator:\n",
    "        testing_loss = testing_forward_pass(X_test_mb,Y_true_test_mb)\n",
    "\n",
    "    print(\"\\nEpoch %d, Testing Loss for last mini batch: %.4f\" % (epoch+1,float(testing_loss)))\n",
    "    testing_acc = test_acc_metric.result()\n",
    "    print(\"Epoch %d, Testing Accuracy: %.2f\" % (epoch+1,float(testing_acc)))\n",
    "    test_acc_metric.reset_states()\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
